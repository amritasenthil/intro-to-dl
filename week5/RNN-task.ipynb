{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "RNN-task.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "etS0hFxCeNSc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "e621b677-f88f-440d-f91e-eb4f8cc6b270"
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week2_honor()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2020-08-31 07:26:24--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-08-31 07:26:24 (57.6 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9t06GP9eIhT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bbb7766a-7357-416d-e6d1-e45dca2194cd"
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONOJTZnXeIhi",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "KZKTHw-ieIho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "52630323-65eb-48c2-bc4a-ba8d4b6e5c66"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4LfKEi3eIh0",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "LJFOnxDueIh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "O4zdP6lCeIh_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "57d4b6eb-b9f1-40c1-814f-e442a1294fd8"
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "LAA11pnYeIiH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "a6155323-6741-4572-d6e6-d001bd60e1f5"
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asfs_BJFeIiN",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPbs6nHDiDME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split(name):\n",
        "  return list(name)\n",
        "\n",
        "l = list(map(split, names))\n",
        "\n",
        "flat_list = []\n",
        "for sublist in l:\n",
        "    for item in sublist:\n",
        "        flat_list.append(item)\n",
        "\n",
        "tokens = list(set(flat_list))\n",
        "tokens.append(pad_token)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZlZM9t9jVGp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "748bf9e5-2864-4720-d12a-eca34e908e63"
      },
      "source": [
        "print(tokens)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['v', 'U', 'J', 'p', 'B', 'V', 'Q', \"'\", 'b', 'o', 'x', 'y', 'z', 'q', 'g', 'G', 'F', 'r', 't', 'm', 'i', ' ', 'A', 'e', '-', 'T', 'S', 'W', 'c', 'H', 'R', 'Z', 'h', 'I', 'f', 'k', 'j', 'X', 'd', 's', 'N', 'l', 'w', 'M', 'u', 'L', 'P', 'E', 'n', 'a', 'D', 'K', 'Y', 'C', 'O', '#']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "EX9uOW2qeIiO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "04a76b57-8856-464b-93ca-c20d770fcfea"
      },
      "source": [
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfV_hj9BeIiS",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "G-L7jL9peIiU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_to_id = dictOfWords = { tokens[i]:i for i in range(0, n_tokens ) }\n",
        " ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q15a77qfp2fn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2e472fbf-3508-4c42-c86a-e7d0e56e0988"
      },
      "source": [
        "token_to_id"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 21,\n",
              " '#': 55,\n",
              " \"'\": 7,\n",
              " '-': 24,\n",
              " 'A': 22,\n",
              " 'B': 4,\n",
              " 'C': 53,\n",
              " 'D': 50,\n",
              " 'E': 47,\n",
              " 'F': 16,\n",
              " 'G': 15,\n",
              " 'H': 29,\n",
              " 'I': 33,\n",
              " 'J': 2,\n",
              " 'K': 51,\n",
              " 'L': 45,\n",
              " 'M': 43,\n",
              " 'N': 40,\n",
              " 'O': 54,\n",
              " 'P': 46,\n",
              " 'Q': 6,\n",
              " 'R': 30,\n",
              " 'S': 26,\n",
              " 'T': 25,\n",
              " 'U': 1,\n",
              " 'V': 5,\n",
              " 'W': 27,\n",
              " 'X': 37,\n",
              " 'Y': 52,\n",
              " 'Z': 31,\n",
              " 'a': 49,\n",
              " 'b': 8,\n",
              " 'c': 28,\n",
              " 'd': 38,\n",
              " 'e': 23,\n",
              " 'f': 34,\n",
              " 'g': 14,\n",
              " 'h': 32,\n",
              " 'i': 20,\n",
              " 'j': 36,\n",
              " 'k': 35,\n",
              " 'l': 41,\n",
              " 'm': 19,\n",
              " 'n': 48,\n",
              " 'o': 9,\n",
              " 'p': 3,\n",
              " 'q': 13,\n",
              " 'r': 17,\n",
              " 's': 39,\n",
              " 't': 18,\n",
              " 'u': 44,\n",
              " 'v': 0,\n",
              " 'w': 42,\n",
              " 'x': 10,\n",
              " 'y': 11,\n",
              " 'z': 12}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "6pT2oOqfeIiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mvou1sf9sl5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cQYLU5dtIgP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "24a208ea-28fc-4c1d-f307-187675357858"
      },
      "source": [
        "names[::2800]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Abagael', ' Konstance', ' Dawson']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "ffdJ7R8ueIic",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "a48de0a3-e4f8-499d-b65c-a0a65dccc8fe"
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[21 22  8 49 14 49 23 41 55]\n",
            " [21 15 41  9 17 11 55 55 55]\n",
            " [21 46 17 20 39 39 20 23 55]\n",
            " [21 15 20  9  0 49 48 48 23]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgD_W47weIif",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/amritasenthil/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "tykRvcWJeIig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "DM_jc5nseIij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='tanh') ### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas =  Dense(n_tokens, activation='softmax') ### YOUR CODE HERE "
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGBDJ8NheIim",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/amritasenthil/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "0V_JP9pJeIin",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = concatenate([x_t_emb, h_t], axis=-1)   ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next =  get_h_next(x_and_h)   ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)  ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kd2fTglDeIip",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "j379KF-WeIiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOi3TqhYeIis",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "lUN1bfx2eIit",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc4ddS8qbVZr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "03ac6315-23b3-4b57-be48-4a37a12ae2ce"
      },
      "source": [
        "print(answers_matrix)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"one_hot:0\", shape=(?, 56), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScfjkhH3bUx5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN5Uxbv9eIiw",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "KRjtXIF0eIiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
        "loss = tf.reduce_mean(loss_function(answers_matrix, predictions_matrix))\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceHgck-keIiz",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9RCPbFFfvhR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1beae86b-8e31-4515-f3fd-9dc3081faec8"
      },
      "source": [
        "print(loss)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "OXXqrxNMeIi0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "2b6cae33-3960-46b4-aaf7-8bb44742a3f2"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55ddUIDaeIi3",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "e0XaSVwLeIi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "eeitgtZpeIi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "DrGgQmIBeIi9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "7dc8d7ef-c021-4692-817f-7c3463a071c6"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Dogty\n",
            " Salon\n",
            " Ay\n",
            " Hanri\n",
            " Anrhtc\n",
            " Giric\n",
            " Kybcin\n",
            " Branla\n",
            " Kaxee\n",
            " Man\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "Tn29tVJ4eIjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-cgYCbzeIjE",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "zB5lWA3UeIjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"spgNoteo6KfkBsih\"\n",
        "COURSERA_EMAIL = \"amrita.senthil@gmail.com\""
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "K0Hq4fepeIjH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "83b55d22-022c-4309-aebc-afa59aae9be0"
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F93-4cd6eIjK",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Ycg83eqHeIjL",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "bDNIfmwseIjL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "ec5e55e5-c970-4af0-c4ea-4b2bc9730adc"
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-64-5f3812e903bf>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-64-5f3812e903bf>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-5f3812e903bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0minput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpredicted_probas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM outputs for each step [batch,time,n_tokens]:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2751\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2752\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 2753\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   2754\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2755\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   2243\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2245\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2246\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2168\u001b[0m         expand_composites=True)\n\u001b[1;32m   2169\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2170\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2171\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2703\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   2704\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 2705\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2706\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    882\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    883\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;31m# Keras cells always wrap state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     return base_layer.Layer.__call__(\n\u001b[0;32m--> 386\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, inputs_shape)\u001b[0m\n\u001b[1;32m    449\u001b[0m       raise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\" %\n\u001b[1;32m    450\u001b[0m                        str(inputs_shape))\n\u001b[0;32m--> 451\u001b[0;31m     \u001b[0m_check_supported_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0minput_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m_check_supported_dtypes\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1345\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m     raise ValueError(\"RNN cell only supports floating point inputs, \"\n\u001b[0;32m-> 1347\u001b[0;31m                      \"but saw dtype: %s\" % dtype)\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: RNN cell only supports floating point inputs, but saw dtype: <dtype: 'int32'>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKQk9JZNeIjO",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "JCfaqfrneIjP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "T_XAWQ99eIjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}