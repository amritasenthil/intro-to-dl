{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "digits_classification.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw3pqbVg1c97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "642b8abc-6e87-4f6a-b9ea-65fe3ffbaa45"
      },
      "source": [
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "setup_google_colab.setup_week2()\n",
        "\n",
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-15 01:47:00--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-07-15 01:47:00 (16.5 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n",
            "**************************************************\n",
            "inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "**************************************************\n",
            "cifar-10-batches-py.tar.gz\n",
            "**************************************************\n",
            "mnist.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwPGo5_X1c-L",
        "colab_type": "text"
      },
      "source": [
        "# MNIST digits classification with TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUh52zUY1c-O",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/amritasenthil/intro-to-dl/blob/master/week2/v2/images/mnist_sample.png?raw=1\" style=\"width:30%\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeQn8gnE1c-R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "43bb9961-3dc8-475f-b184-02772237701d"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "print(\"We're using TF\", tf.__version__)\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../..\")\n",
        "import grading\n",
        "\n",
        "import matplotlib_utils\n",
        "from importlib import reload\n",
        "reload(matplotlib_utils)\n",
        "\n",
        "import grading_utils\n",
        "reload(grading_utils)\n",
        "\n",
        "import keras_utils\n",
        "from keras_utils import reset_tf_session"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We're using TF 1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ATGhGCS1c-c",
        "colab_type": "text"
      },
      "source": [
        "# Fill in your Coursera token and email\n",
        "To successfully submit your answers to our grader, please fill in your Coursera submission token and email"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0r0MrJGq1c-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grader = grading.Grader(assignment_key=\"XtD7ho3TEeiHQBLWejjYAA\", \n",
        "                        all_parts=[\"9XaAS\", \"vmogZ\", \"RMv95\", \"i8bgs\", \"rE763\"])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tfh7qqt-1c-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"pALwVfTtvx41KxUb\"\n",
        "COURSERA_EMAIL = \"amrita.senthil@gmail.com\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3_v8bER1c-y",
        "colab_type": "text"
      },
      "source": [
        "# Look at the data\n",
        "\n",
        "In this task we have 50000 28x28 images of digits from 0 to 9.\n",
        "We will train a classifier on this data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3pA2mKF1c-z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a8ebcf8e-3cc0-438b-9ab7-d2ffe5582490"
      },
      "source": [
        "import preprocessed_mnist\n",
        "X_train, y_train, X_val, y_val, X_test, y_test = preprocessed_mnist.load_dataset()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            " 9379840/11490434 [=======================>......] - ETA: 0s"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhRTjyma1c-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "outputId": "dd540b14-ab22-4cfc-b8fc-3b76a7630992"
      },
      "source": [
        "# X contains rgb values divided by 255\n",
        "print(\"X_train [shape %s] sample patch:\\n\" % (str(X_train.shape)), X_train[1, 15:20, 5:10])\n",
        "print(\"A closeup of a sample patch:\")\n",
        "plt.imshow(X_train[1, 15:20, 5:10], cmap=\"Greys\")\n",
        "plt.show()\n",
        "print(\"And the whole sample:\")\n",
        "plt.imshow(X_train[1], cmap=\"Greys\")\n",
        "plt.show()\n",
        "print(\"y_train [shape %s] 10 samples:\\n\" % (str(y_train.shape)), y_train[:10])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train [shape (50000, 28, 28)] sample patch:\n",
            " [[0.         0.29803922 0.96470588 0.98823529 0.43921569]\n",
            " [0.         0.33333333 0.98823529 0.90196078 0.09803922]\n",
            " [0.         0.33333333 0.98823529 0.8745098  0.        ]\n",
            " [0.         0.33333333 0.98823529 0.56862745 0.        ]\n",
            " [0.         0.3372549  0.99215686 0.88235294 0.        ]]\n",
            "A closeup of a sample patch:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "And the whole sample:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "y_train [shape (50000,)] 10 samples:\n",
            " [5 0 4 1 9 2 1 3 1 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agt1909t1c_H",
        "colab_type": "text"
      },
      "source": [
        "# Linear model\n",
        "\n",
        "Your task is to train a linear classifier $\\vec{x} \\rightarrow y$ with SGD using TensorFlow.\n",
        "\n",
        "You will need to calculate a logit (a linear transformation) $z_k$ for each class: \n",
        "$$z_k = \\vec{x} \\cdot \\vec{w_k} + b_k \\quad k = 0..9$$\n",
        "\n",
        "And transform logits $z_k$ to valid probabilities $p_k$ with softmax: \n",
        "$$p_k = \\frac{e^{z_k}}{\\sum_{i=0}^{9}{e^{z_i}}} \\quad k = 0..9$$\n",
        "\n",
        "We will use a cross-entropy loss to train our multi-class classifier:\n",
        "$$\\text{cross-entropy}(y, p) = -\\sum_{k=0}^{9}{\\log(p_k)[y = k]}$$ \n",
        "\n",
        "where \n",
        "$$\n",
        "[x]=\\begin{cases}\n",
        "       1, \\quad \\text{if $x$ is true} \\\\\n",
        "       0, \\quad \\text{otherwise}\n",
        "    \\end{cases}\n",
        "$$\n",
        "\n",
        "Cross-entropy minimization pushes $p_k$ close to 1 when $y = k$, which is what we want.\n",
        "\n",
        "Here's the plan:\n",
        "* Flatten the images (28x28 -> 784) with `X_train.reshape((X_train.shape[0], -1))` to simplify our linear model implementation\n",
        "* Use a matrix placeholder for flattened `X_train`\n",
        "* Convert `y_train` to one-hot encoded vectors that are needed for cross-entropy\n",
        "* Use a shared variable `W` for all weights (a column $\\vec{w_k}$ per class) and `b` for all biases.\n",
        "* Aim for ~0.93 validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnGrYhn_1c_I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fbe536f0-b33e-4a36-ed5b-da96ac9fca12"
      },
      "source": [
        "X_train_flat = X_train.reshape((X_train.shape[0], -1))\n",
        "print(X_train_flat.shape)\n",
        "\n",
        "X_val_flat = X_val.reshape((X_val.shape[0], -1))\n",
        "print(X_val_flat.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGSgcvcW1c_S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "outputId": "1260e2fc-2277-4f9c-ed28-5705a9a20fc4"
      },
      "source": [
        "import keras\n",
        "\n",
        "y_train_oh = keras.utils.to_categorical(y_train, 10)\n",
        "y_val_oh = keras.utils.to_categorical(y_val, 10)\n",
        "\n",
        "print(y_train_oh.shape)\n",
        "print(y_train_oh[:3], y_train[:3])\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 10)\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]] [5 0 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-47fc11b3777a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_oh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_oh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'type'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MO64q6A21c_Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "81372962-22f3-489f-a31d-6c6c28a9eabf"
      },
      "source": [
        "# run this again if you remake your graph\n",
        "s = reset_tf_session()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O98UzeMy1c_e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "311fba89-1e3e-4a72-d1d7-74b50c6daf46"
      },
      "source": [
        "# Model parameters: W and b\n",
        "W = tf.get_variable(\"W\", shape=(X_train_flat.shape[1], 10), dtype = tf.float32) ### YOUR CODE HERE ### tf.get_variable(...) with shape[0] = 784\n",
        "b = tf.get_variable(\"b\", shape=(10,1), dtype= tf.float32) ### YOUR CODE HERE ### tf.get_variable(...)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-8ef3cfcdd69e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Model parameters: W and b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### YOUR CODE HERE ### tf.get_variable(...) with shape[0] = 784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### YOUR CODE HERE ### tf.get_variable(...)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1498\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1241\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m   def _get_partitioned_variable(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    565\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m   def _get_partitioned_variable(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    517\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     synchronization, aggregation, trainable = (\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    866\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"tensorflow/python\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" %\n\u001b[0;32m--> 868\u001b[0;31m                          (err_msg, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    869\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Variable W already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJoEbTM51c_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Placeholders for the input data\n",
        "input_X =tf.placeholder(tf.float32, shape=(None, X_train_flat.shape[1])) ### YOUR CODE HERE ### tf.placeholder(...) for flat X with shape[0] = None for any batch size\n",
        "input_y = tf.placeholder(tf.float32, shape=(None, 10))### YOUR CODE HERE ### tf.placeholder(...) for one-hot encoded true labels"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slodc-56Pw2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "1dd98a51-a083-4745-f480-1f7d9d328548"
      },
      "source": [
        "tf.get_default_graph().get_operations()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Operation 'keras_learning_phase' type=Placeholder>,\n",
              " <tf.Operation 'W/Initializer/random_uniform/shape' type=Const>,\n",
              " <tf.Operation 'W/Initializer/random_uniform/min' type=Const>,\n",
              " <tf.Operation 'W/Initializer/random_uniform/max' type=Const>,\n",
              " <tf.Operation 'W/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
              " <tf.Operation 'W/Initializer/random_uniform/sub' type=Sub>,\n",
              " <tf.Operation 'W/Initializer/random_uniform/mul' type=Mul>,\n",
              " <tf.Operation 'W/Initializer/random_uniform' type=Add>,\n",
              " <tf.Operation 'W' type=VariableV2>,\n",
              " <tf.Operation 'W/Assign' type=Assign>,\n",
              " <tf.Operation 'W/read' type=Identity>,\n",
              " <tf.Operation 'b/Initializer/random_uniform/shape' type=Const>,\n",
              " <tf.Operation 'b/Initializer/random_uniform/min' type=Const>,\n",
              " <tf.Operation 'b/Initializer/random_uniform/max' type=Const>,\n",
              " <tf.Operation 'b/Initializer/random_uniform/RandomUniform' type=RandomUniform>,\n",
              " <tf.Operation 'b/Initializer/random_uniform/sub' type=Sub>,\n",
              " <tf.Operation 'b/Initializer/random_uniform/mul' type=Mul>,\n",
              " <tf.Operation 'b/Initializer/random_uniform' type=Add>,\n",
              " <tf.Operation 'b' type=VariableV2>,\n",
              " <tf.Operation 'b/Assign' type=Assign>,\n",
              " <tf.Operation 'b/read' type=Identity>,\n",
              " <tf.Operation 'Placeholder' type=Placeholder>,\n",
              " <tf.Operation 'Placeholder_1' type=Placeholder>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILp4JPzA1c_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute predictions\n",
        "logits = tf.tensordot(X_input_flat, W) ### YOUR CODE HERE ### logits for input_X, resulting shape should be [input_X.shape[0], 10]\n",
        "probas = tf.nn.softmax(logits) ### YOUR CODE HERE ### apply tf.nn.softmax to logits\n",
        "classes = tf.argmax(probas)### YOUR CODE HERE ### apply tf.argmax to find a class index with highest probability\n",
        "\n",
        "# Loss should be a scalar number: average loss over all the objects with tf.reduce_mean().\n",
        "# Use tf.nn.softmax_cross_entropy_with_logits on top of one-hot encoded input_y and logits.\n",
        "# It is identical to calculating cross-entropy on top of probas, but is more numerically friendly (read the docs).\n",
        "loss = ### YOUR CODE HERE ### cross-entropy loss\n",
        "\n",
        "# Use a default tf.train.AdamOptimizer to get an SGD step\n",
        "step = ### YOUR CODE HERE ### optimizer step that minimizes the loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "bdDXOp5K1c_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "BATCH_SIZE = 512\n",
        "EPOCHS = 40\n",
        "\n",
        "# for logging the progress right here in Jupyter (for those who don't have TensorBoard)\n",
        "simpleTrainingCurves = matplotlib_utils.SimpleTrainingCurves(\"cross-entropy\", \"accuracy\")\n",
        "\n",
        "for epoch in range(EPOCHS):  # we finish an epoch when we've looked at all training samples\n",
        "    \n",
        "    batch_losses = []\n",
        "    for batch_start in range(0, X_train_flat.shape[0], BATCH_SIZE):  # data is already shuffled\n",
        "        _, batch_loss = s.run([step, loss], {input_X: X_train_flat[batch_start:batch_start+BATCH_SIZE], \n",
        "                                             input_y: y_train_oh[batch_start:batch_start+BATCH_SIZE]})\n",
        "        # collect batch losses, this is almost free as we need a forward pass for backprop anyway\n",
        "        batch_losses.append(batch_loss)\n",
        "\n",
        "    train_loss = np.mean(batch_losses)\n",
        "    val_loss = s.run(loss, {input_X: X_val_flat, input_y: y_val_oh})  # this part is usually small\n",
        "    train_accuracy = accuracy_score(y_train, s.run(classes, {input_X: X_train_flat}))  # this is slow and usually skipped\n",
        "    valid_accuracy = accuracy_score(y_val, s.run(classes, {input_X: X_val_flat}))  \n",
        "    simpleTrainingCurves.add(train_loss, val_loss, train_accuracy, valid_accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrzIVn021c_w",
        "colab_type": "text"
      },
      "source": [
        "# Submit a linear model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfMooHqf1c_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## GRADED PART, DO NOT CHANGE!\n",
        "# Testing shapes \n",
        "grader.set_answer(\"9XaAS\", grading_utils.get_tensors_shapes_string([W, b, input_X, input_y, logits, probas, classes]))\n",
        "# Validation loss\n",
        "grader.set_answer(\"vmogZ\", s.run(loss, {input_X: X_val_flat, input_y: y_val_oh}))\n",
        "# Validation accuracy\n",
        "grader.set_answer(\"RMv95\", accuracy_score(y_val, s.run(classes, {input_X: X_val_flat})))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H6mRFQF1c_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# you can make submission with answers so far to check yourself at this stage\n",
        "grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G97mBMcm1c_2",
        "colab_type": "text"
      },
      "source": [
        "# MLP with hidden layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkNn0m871c_3",
        "colab_type": "text"
      },
      "source": [
        "Previously we've coded a dense layer with matrix multiplication by hand. \n",
        "But this is not convenient, you have to create a lot of variables and your code becomes a mess. \n",
        "In TensorFlow there's an easier way to make a dense layer:\n",
        "```python\n",
        "hidden1 = tf.layers.dense(inputs, 256, activation=tf.nn.sigmoid)\n",
        "```\n",
        "\n",
        "That will create all the necessary variables automatically.\n",
        "Here you can also choose an activation function (remember that we need it for a hidden layer!).\n",
        "\n",
        "Now define the MLP with 2 hidden layers and restart training with the cell above.\n",
        "\n",
        "You're aiming for ~0.97 validation accuracy here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm6lLdle1c_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# write the code here to get a new `step` operation and then run the cell with training loop above.\n",
        "# name your variables in the same way (e.g. logits, probas, classes, etc) for safety.\n",
        "### YOUR CODE HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuyWq8Yk1c_6",
        "colab_type": "text"
      },
      "source": [
        "# Submit the MLP with 2 hidden layers\n",
        "Run these cells after training the MLP with 2 hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdGAUpuL1c_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## GRADED PART, DO NOT CHANGE!\n",
        "# Validation loss for MLP\n",
        "grader.set_answer(\"i8bgs\", s.run(loss, {input_X: X_val_flat, input_y: y_val_oh}))\n",
        "# Validation accuracy for MLP\n",
        "grader.set_answer(\"rE763\", accuracy_score(y_val, s.run(classes, {input_X: X_val_flat})))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtXmQG2F1c_-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# you can make submission with answers so far to check yourself at this stage\n",
        "grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMJKWK2P1dAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}